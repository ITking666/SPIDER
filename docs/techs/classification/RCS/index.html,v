head	1.3;
access;
symbols;
locks; strict;
comment	@# @;


1.3
date	2019.01.31.16.04.57;	author leith;	state Exp;
branches;
next	1.2;

1.2
date	2008.12.15.19.49.37;	author leith;	state Exp;
branches;
next	1.1;

1.1
date	2008.12.15.19.37.41;	author leith;	state Exp;
branches;
next	;


desc
@old
@


1.3
log
@cosmetic & fixed deleted words
@
text
@<html>

<head>
<title>Classification of images</title>
</head>

<body>

<b><h2 align="center">Classification of Images</h2></b>


<p>
<a href="../../glossary.html#Classification">Classification</a> is a 
computational procedure that sorts images into groups ("classes")
according to their similarities.  Images can be similar in all kinds of
ways, but in EM-related image processing we use a very strict measure
of similarity that is based on a pixel-by-pixel comparison: the mean
squared difference, a.k.a. <i>generalized Euclidean distance</i>.
</p>

<p>
Images represented by N x N arrays of density values can be thought of
as points in an N x N-dimensional space.  Points that are close to each
other in that space represent images that are "similar" since the mean
squared difference between their pixel values is small
</p>

<p>

<img src="classif.jpg" align="left">

There are two different approaches to classification: <i>supervised</i>
and <i>unsupervised</i>.  Both make use of the similarity measure
introduced above,
 but one (supervised) classifies a set of images according to their
 similarity (speak: closeness in our high-dimensional space) with
certain pre-given images ("references" or "templates"), the other
(unsupervised) classifies the images according to their intrinsic
grouping or clustering within the set.
</p>

<p>This is demonstrated schematically in the figure.  The same set of
images, represented by a set of dots, is either classified by comparing
each image with a set of references (represented by fat dots), or by
dividing the whole cloud of dots into clusters (indicated by dashed
line).
</p>

<p>
For simplification of the analysis, or for the purpose of increasing
the signal-to-noise ratio, classification is often carried out in a
space that is of much lower dimensionality than the initial N x N
space.  This reduction of dimensionality is achieved by  
<a href="../MSA/index.html">Multivariate Data Analysis</a> 
(also known as multivariate statistical analysis).  

The two most common reduction techniques used in EM are 
<a href="../../glossary.html#Correspondence">correspondence analysis</a> 
and principal component analysis</a>. 
</p>

<p>
For further info see the <a href="tutorial.html"> classification and clustering tutorial</a>.
</p>

</body>

</html>
@


1.2
log
@cosmetic
@
text
@d25 1
d53 3
a55 3
space.  This reduction of dimensionality is achieved by Multivariate
Data Analysis (also known as 
<a href="../MSA/index.htm">multivariate statistical analysis</a>).  
d57 1
a57 1
The two most common techniques in EM are 
a61 1

d63 1
a63 1
For further info see the <a href="tutorial.html">tutorial</a> on classification and clustering.
@


1.1
log
@Initial revision
@
text
@d2 1
d7 3
a9 1
<body bgcolor="#ffffff" text="#000000" link="#0000ff" vlink="#800080" alink="#ff0000">
a10 1
<b><h2>Classification of Images</h2></b>
d12 1
a12 3
<p></p>
see the <a href="tutorial.html">tutorial on classification and clustering</a>
<p></p>
d14 12
a25 13
computational procedure that sorts images into groups 
("classes") according to their similarities.  Images can be similar in all kinds
of ways, but in EM-related image processing we use a very strict measure of 
similarity that is based on a pixel-by-pixel comparison: the mean squared 
difference, a.k.a. <i>generalized Euclidean distance</i>.

<p></p>

Images represented by N x N arrays of density values can be thought of as points
 in an N x N-dimensional space.  Points that are close to each other in that
 space represent images that are "similar" since the mean squared difference
 between their pixel values is small.
<p></p>
d27 2
d31 23
a53 19
There are two different approaches to classification: <i>supervised</i> and 
 <i>unsupervised</i>.  Both make use of the similarity measure introduced above, 
 but one (supervised) classifies a set of images according to their similarity 
(speak: closeness in our high-dimensional space) with certain pre-given images 
("references" or "templates"), the other (unsupervised) classifies the images 
according to their intrinsic grouping or clustering within the set.
<p></p>


This is demonstrated schematically in the figure.  The same set of images, 
represented by a set of dots, is either classified by comparing each image with 
a set of references (represented by fat dots), or by dividing the whole cloud 
of dots into clusters (indicated by dashed line).
<p></p>

For simplification of the analysis, or for the purpose of increasing the 
signal-to-noise ratio, classification is often carried out in a space that 
is of much lower dimensionality than the initial N x N space.  This reduction 
of dimensionality is achieved by Multivariate Data Analysis (also known as 
d55 1
d58 8
a65 1
and principal component analysis</a>.  
@
