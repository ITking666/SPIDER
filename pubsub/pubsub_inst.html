<html>

<head>
<title>Installing and Managing SPIDER's PubSub System for Distributed Processing</title>
</head>

<body>
<p /.
<h1 align="center">Installing and Managing  SPIDER's PubSub System for Distributed Processing</h1>


<h3 align="left">Introduction </h3>
   
With PubSub, <a href="../docs/user_doc.html">SPIDER procedures</a> 
can be run in parallel on a distributed cluster of computers or within a single cluster. 
The user places his SPIDER job in a shared que.  Each of the subscriber
machines can take jobs from the que.  Each subscriber machine
can specify when it will take jobs and how many jobs it can take at
a time.  If the machines vary greatly in processing power, it is best
to partition the SPIDER jobs so that they will take
a reasonable length of time (e.g. 20...100 minutes) so 
that the subscription process is most efficient.    
</p>

<hr />

<h2 align="center">Installing PubSub</h2>

<h4 align="left">Requirements for PubSub </h4>

<ol>
<li>  <p> Systems must have Perl and standard POSIX utilities.<br/>
      (If Perl is not located in: <i>/usr/bin/perl</i> you will have to
      place a link there or alter the first line of each Perl script.) 
      </p> </li> 

<li>  <p>Systems must have disks cross-mounted so that they are accessible from
      all processors using same path e.g. <i>/net/location/</i>. 
      </p></li>

<li>  <p>Systems must be able to use <i>rsh</i> to run operations remotely
      on all computers in the cluster. If your systems only support <i>rsh</i> 
      you will have to alter the Perl scripts. 
      </p></li>

<li>  <p>The file which will be used for the <i>'publisher que'</i> must have 
      <i>'read/write'</i> permissions suitable for all users.
      </p></li>
</ol>


<a name="install"><h4 align="left ">PubSub Software Installation</h4></a>

<ol>

<li>  <p>Create environment variables <i>PUBSUB_DIR</i> for the location of the
      PubSub installation directory and <i>PUBSUB_MASTER</i> for name of the host
      where PubSub master is run.  These environment variables must be set in 
      each users startup file (i.e. for csh users in their <i>.cshrc file</i>) e.g.  <br/> 
      <b> setenv  &nbsp; PUBSUB_DIR    &nbsp; /usr8/spider/pubsub</b> </br> 
      <b> setenv  &nbsp; PUBSUB_MASTER &nbsp; radha</b> 
      </li></p>

<li>  <p>Following steps should be done when logged in on PUBSUB_MASTER as member of
      <i> group</i> that is planning on using <i>PubSub</i> 
      <b> NOT</b> as: <i>root</i> 
      </li></p>

<li>  <p>cd <i>PUBSUB_DIRECTORY</i> e.g.  <br/>
      <b> mkdir &nbsp; $PUBSUB_DIR ; &nbsp; cd $PUBSUB_DIR</b> 
      </li></p>

<li>  <p>Copy the PubSub files normally distributed in: 
      <i>SPIDER_DIR/pubsub</i> to your  PUBSUB_DIRECTORY e.g.   <br/>
      <b>cp &nbsp; SPIDER_DIR/pubsub/* &nbsp; $PUBSUB_DIR </b>
      </li></p>

<li> <p>Edit <a href="pubsub.permit">pubsub.permit</a>  e.g. <br/>
       <b>xedit  pubsub.permit</b><br/>
       Set machine specific permissions. Currently contains: machine name, limit for
       number of simultaneous jobs, permitted run days, permitted start-time, permitted end-time, and que check
       frequency (seconds), and comments. The machine names here determine where jobs can
       be run.
       </p></li>

<li> <p>Create an empty <i>que file</i>  e.g. <br\>
       <b>touch  pubsub.que</b>               <br/>
       </p></li>

<li> <p>Tune NFS (if master node responds slowly). <br/>
        If your master and compute nodes node will be accessing lots of data from a NFS mounted disk
        you may want to speed up the process by altering the <i>/etc/fstab</i>
        mount for the data disks to increase the read and write buffersize e.g.:<br/>
        <code>tonga2:/usr6       /usr6    nfs   rsize=8192,wsize=8192 0 0</code><br/>
        See: <a href="http://nnfsstatfs.sourceforge.net/nfs-howto/performance.html">NFS tuning</a>
        for discussion.
        </p><p>
        You also may want to increase the number of nfs threads on the master node
        and any other machines where the data is located using:   <br/>
        <code>/usr/sbin/rpc.nfsd  nproc </code>                   <br/>
        This should be placed in your <i>init</i> file so that it will be
        preserved on reboot.  On redhat GNU/Linux this is set in:
        <i>/etc/rc.d/init.d/nfs</i>.   Both changes will require <i>root</I> access
        to the machine.  See your Unix manual pages for: <i> fstab &amp; nfsd</i>
        </p></li>
</ol>

<hr />
<p />

<a name="install"><h2 align="center">Managing PubSub</h2></a>

<a name="started"><h4 align="left">Starting PubSub</h4></a>
<ol>

     <p><li>Login to the PubSub master &nbsp;&nbsp; e.g.<br/>
     <b> ssh radha</b>
     </li></p>

     <p><li>cd YOUR_PUBSUB_DIRECTORY &nbsp;&nbsp; e.g. <br/>
     <b>cd &nbsp; $PUBSUB_DIR</b> 
     </li></p>

     <li> Run <a href="startsub.perl">startsub.perl</a> to start a subscription 
     process on this master node. If this process dies you will have to restart 
     it again in the same way. &nbsp;&nbsp; e.g. <br/>
     <b>startsub.perl</b>
     </li></p>

 </ol>


<h4 align="left">Removing a compute node from PubSub Use</h4>
<ol>
     <p><li>Login to the PubSub master &nbsp;&nbsp; e.g.<br/>
     <b> ssh radha</b>
     </li></p>

     <p><li>cd YOUR_PUBSUB_DIRECTORY &nbsp;&nbsp; e.g. <br/>
     <b>cd &nbsp; $PUBSUB_DIR</b> 
     </li></p>

     <p><li> Edit: <a href="killsub">pubsub.permit</a> and comment out 
      the nodes by adding a '#' before machine name &nbsp;&nbsp; e.g. <br/>
     <b> #node105     1        7     00:00      23:59      60 </b> </li></p>
</ol>


<h4 align="left">Removing a Rogue Job from PubSub Que</h4>
<ol>
     <p><li>Login to the PubSub master &nbsp;&nbsp; e.g.<br/>
     <b> ssh radha</b>
     </li></p>

     <p><li>cd YOUR_PUBSUB_DIRECTORY &nbsp;&nbsp; e.g. <br/>
     <b>cd &nbsp; $PUBSUB_DIR</b> 
     </li></p>

     <li> Run <a href="status">status</a> to list process numbers id's que. &nbsp;&nbsp; e.g. <br/>
     <b>status</b> 
     </li></p>

     <li> Run <a href="fixque.perl">fixque.perl</a> to delete process from que. (Keep the
         negative sign if present) e.g. <br/> 
     <b>fixque.perl <i>process id</i> </b>
     </li></p>
</ol>


<h4 align="left">List jobs on compute nodes</h4>
<ol>
     <p><li>Login to the PubSub master &nbsp;&nbsp; e.g.<br/>
     <b> ssh radha</b>
     </li></p>

     <li> Run <a href="wherespi">wherespi</a>   e.g. <br/> 
     <b>wherespi </b>
     </li></p>
</ol>

<h4 align="left">Killing your master SPIDER job under PubSub </h4>

<ol>
     <p><li>Login to the PubSub master  &nbsp;&nbsp; e.g.<br/>
     <b> ssh radha</b>
     </li></p>

     <li> Run <i>ps</i> to get process id.  &nbsp;&nbsp; e.g. <br/>
     <b>ps -ef | grep username</b> 
     </li></p>

     <li>Kill the process. &nbsp;&nbsp; e.g. <br/>
     <b>kill -9 <i>process id</i></b>
     </li></p>
</ol>


<h4 align="left">Killing your compute node SPIDER jobs under PubSub </h4>

<ol>
     <p><li>Login to the PubSub master  &nbsp;&nbsp; e.g.<br/>
     <b> ssh radha</b>
     </li></p>

     <li> Run <i>killspi</i> to delete all of your SPIDER jobs running
          on all compute nodes from this cluster.  &nbsp;&nbsp; e.g. <br/>
     <b><a href="killspi">killspi</a></b> 
     </li></p>
</ol>

<h4 align="left">Running SPIDER jobs using PubSub</h4>
<p>
<ol> See <a href="./pubsub.html">use of PubSub</a>.
</p>

</ol>

<hr></hr>
    

<h2 align="center">PubSub components</h2> 

Note: You do not need to understand this to utilize PubSub.  Perl code which may have 
to be altered since it may be site specific is marked with <b>%%%%</b> in the 
source files.

<dl>
<p>
<dt><a href="startsub.perl">startsub.perl</a></dt>
<dd> Start subscriber process. </dd></p>
   
<p>
<dt><a href="subscribe.perl">subscribe.perl</a></dt>
<dd> Subscriber process.  Watches <i>publisher que</i> for any
new jobs.  If job appears, the subscriber looks for a suitable machine. When
a machine is found the subscriber signals the publishing process where to run the
job.  This subscriber process checks the publisher que at
specified frequency until it dies or is "killed'.</dd></p>
   
<p>
<dt><a href="publish.perl">publish.perl</a></dt>
<dd>Submits a job to the publisher que.  System <i>flock</i> is used internally to
avoid update collisions.</dd></p>
   
<p>
<dt><a href="delete.perl">delete.perl</a></dt>
<dd>Places job statistics in <i>pubsub.log</i> when a job is finished. 
    System <i>flock</i> is used to avoid update collisions.</dd></p>
   
<p>
<dt><a href="pubsub.permit">pubsub.permit</a></dt>
<dd>A single shared file containing machine specific permissions.  Currently
contains: machine name, limit for number of simultaneous jobs, 
permitted run days, permitted start-time, permitted  end-time, and 
que check frequency (seconds), and comments.
</dd></p>

<p>
<dt><a href="pubsub.que">pubsub.que</a></dt>
<dd>Publisher que.  This is a single shared file that is accessed by the
subscriber process to obtain jobs.  System <i>flock</i> is used to
avoid update collisions.  The job number becomes negative when a
job is 'subscribed' to. Jobs are deleted from the que
when <a href="delete.perl">delete.perl</a> runs.</dd></p>   

<p>
<dt><a href="killsub">killsub</a></dt>
<dd>Kills the PubSub subcriber process.</dd></p>   

<p>
<dt><a href="wherespi">wherespi</a></dt>
<dd>Should tell you where SPIDER is currently running on all nodes. This is
     currently specific to our installation.<dd></p>   

<p>
<dt><a href="pubsub.log">pubsub.log</a></dt>
<dd>PubSub log.  This is a  file that is created in the user's directory
to log job progress.  System <i>flock</i> is used to
avoid update collisions.  The run time for the job run is
recorded here as well as the node name.</dd></p>   

</dl>
   
<hr>

<p> <small>
Source:      spider/pubsub/pubsub_inst.html  &nbsp;&nbsp;&nbsp;  
Last page update: 10 Aug. 2010  &nbsp;&nbsp;&nbsp;
ArDean Leith  
</small> <p>

</body>
</html>
